{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model on Diff Data\n",
    "USA World Series Results,\n",
    "Run on \"Diff\" data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Opp</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Poss_Time_Diff</th>\n",
       "      <th>Score_Diff</th>\n",
       "      <th>Conv_Diff</th>\n",
       "      <th>Tries_Diff</th>\n",
       "      <th>Passes_Diff</th>\n",
       "      <th>Contestable_KO_Win_pct_Diff</th>\n",
       "      <th>PenFK_Against_Diff</th>\n",
       "      <th>RuckMaul_Diff</th>\n",
       "      <th>...</th>\n",
       "      <th>-99 : -75</th>\n",
       "      <th>-74 : -25</th>\n",
       "      <th>-24 : -1</th>\n",
       "      <th>0 : 25</th>\n",
       "      <th>26 : 50</th>\n",
       "      <th>51 : 75</th>\n",
       "      <th>76 : 100</th>\n",
       "      <th>101 : 125</th>\n",
       "      <th>126 : 150</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>2015_Cape_Town</td>\n",
       "      <td>13.966480</td>\n",
       "      <td>-10.638298</td>\n",
       "      <td>-14.285714</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>25.925926</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WALES</td>\n",
       "      <td>2015_Cape_Town</td>\n",
       "      <td>7.471264</td>\n",
       "      <td>15.555556</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>27.868852</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KENYA</td>\n",
       "      <td>2015_Cape_Town</td>\n",
       "      <td>-33.136095</td>\n",
       "      <td>-44.444444</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-10.638298</td>\n",
       "      <td>-16.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW ZEALAND</td>\n",
       "      <td>2015_Cape_Town</td>\n",
       "      <td>51.758794</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.119403</td>\n",
       "      <td>-75.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FIJI</td>\n",
       "      <td>2015_Cape_Town</td>\n",
       "      <td>12.880562</td>\n",
       "      <td>-20.833333</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Opp      Tournament  Poss_Time_Diff  Score_Diff  Conv_Diff  \\\n",
       "0    AUSTRALIA  2015_Cape_Town       13.966480  -10.638298 -14.285714   \n",
       "1        WALES  2015_Cape_Town        7.471264   15.555556  14.285714   \n",
       "2        KENYA  2015_Cape_Town      -33.136095  -44.444444 -33.333333   \n",
       "3  NEW ZEALAND  2015_Cape_Town       51.758794   33.333333  33.333333   \n",
       "4         FIJI  2015_Cape_Town       12.880562  -20.833333 -25.000000   \n",
       "\n",
       "   Tries_Diff  Passes_Diff  Contestable_KO_Win_pct_Diff  PenFK_Against_Diff  \\\n",
       "0    0.250000    25.925926                   -50.000000            0.000000   \n",
       "1    0.083333    27.868852                    25.000000          -20.000000   \n",
       "2   -0.750000   -10.638298                   -16.666667           66.666667   \n",
       "3    0.000000    76.119403                   -75.000000          -50.000000   \n",
       "4    0.266667    38.461538                   -66.666667          -33.333333   \n",
       "\n",
       "   RuckMaul_Diff   ...    -99 : -75  -74 : -25  -24 : -1  0 : 25  26 : 50  \\\n",
       "0       0.000000   ...          0.0      -12.5       0.0     0.0      0.0   \n",
       "1    -100.000000   ...          0.0        0.0       0.0    12.5      0.0   \n",
       "2      60.000000   ...          0.0        0.0      -5.0     0.0      0.0   \n",
       "3    -100.000000   ...        -37.5        0.0       0.0     0.0      0.0   \n",
       "4     -33.333333   ...          0.0      -12.5       0.0     0.0      0.0   \n",
       "\n",
       "   51 : 75  76 : 100  101 : 125  126 : 150  Result  \n",
       "0      0.0       0.0        0.0        0.0       0  \n",
       "1      0.0       0.0        0.0        0.0       1  \n",
       "2      0.0       0.0        0.0        0.0       0  \n",
       "3      0.0       0.0        0.0        0.0       1  \n",
       "4      0.0       0.0        0.0        0.0       0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Data - only want USA matches\n",
    "df = pd.read_csv(\"../data/output/new_features_diffdata.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156 entries, 0 to 155\n",
      "Data columns (total 27 columns):\n",
      "Opp                            156 non-null object\n",
      "Tournament                     156 non-null object\n",
      "Poss_Time_Diff                 156 non-null float64\n",
      "Score_Diff                     156 non-null float64\n",
      "Conv_Diff                      156 non-null float64\n",
      "Tries_Diff                     156 non-null float64\n",
      "Passes_Diff                    156 non-null float64\n",
      "Contestable_KO_Win_pct_Diff    156 non-null float64\n",
      "PenFK_Against_Diff             156 non-null float64\n",
      "RuckMaul_Diff                  156 non-null float64\n",
      "Ruck_Win_pct_Diff              156 non-null float64\n",
      "Cards_diff                     156 non-null float64\n",
      "Lineout_Win_Pct_Diff           156 non-null float64\n",
      "Scrum_Win_Pct_Diff             156 non-null float64\n",
      "-175 : -150                    156 non-null float64\n",
      "-149 : -125                    156 non-null float64\n",
      "-124 : -100                    156 non-null float64\n",
      "-99 : -75                      156 non-null float64\n",
      "-74 : -25                      156 non-null float64\n",
      "-24 : -1                       156 non-null float64\n",
      "0 : 25                         156 non-null float64\n",
      "26 : 50                        156 non-null float64\n",
      "51 : 75                        156 non-null float64\n",
      "76 : 100                       156 non-null float64\n",
      "101 : 125                      156 non-null float64\n",
      "126 : 150                      156 non-null float64\n",
      "Result                         156 non-null int64\n",
      "dtypes: float64(24), int64(1), object(2)\n",
      "memory usage: 33.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Opp',\n",
       " 'Tournament',\n",
       " 'Poss_Time_Diff',\n",
       " 'Score_Diff',\n",
       " 'Conv_Diff',\n",
       " 'Tries_Diff',\n",
       " 'Passes_Diff',\n",
       " 'Contestable_KO_Win_pct_Diff',\n",
       " 'PenFK_Against_Diff',\n",
       " 'RuckMaul_Diff',\n",
       " 'Ruck_Win_pct_Diff',\n",
       " 'Cards_diff',\n",
       " 'Lineout_Win_Pct_Diff',\n",
       " 'Scrum_Win_Pct_Diff',\n",
       " '-175 : -150',\n",
       " '-149 : -125',\n",
       " '-124 : -100',\n",
       " '-99 : -75',\n",
       " '-74 : -25',\n",
       " '-24 : -1',\n",
       " '0 : 25',\n",
       " '26 : 50',\n",
       " '51 : 75',\n",
       " '76 : 100',\n",
       " '101 : 125',\n",
       " '126 : 150',\n",
       " 'Result']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of features to drop that are unneccessary or will bias the prediction\n",
    "droplist = ['Opp', 'Score_Diff', 'Tries_Diff','Tournament', 'Conv_Diff','-175 : -150', '-149 : -125','-124 : -100', '-99 : -75', '-74 : -25','-24 : -1','0 : 25','26 : 50','51 : 75','76 : 100','101 : 125','126 : 150']\n",
    "\n",
    "xg_data = df.drop((droplist), axis=1)\n",
    "\n",
    "#Drop rows with Result == \"T\" (Ties). This label messes up classification models\n",
    "xg_data.drop(xg_data[xg_data.Result == 2].index, inplace=True)\n",
    "\n",
    "#Pull out the variable we're trying to predict: 'Result'\n",
    "X = xg_data.drop('Result',axis=1)\n",
    "y = xg_data['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Poss_Time_Diff</th>\n",
       "      <th>Passes_Diff</th>\n",
       "      <th>Contestable_KO_Win_pct_Diff</th>\n",
       "      <th>PenFK_Against_Diff</th>\n",
       "      <th>RuckMaul_Diff</th>\n",
       "      <th>Ruck_Win_pct_Diff</th>\n",
       "      <th>Cards_diff</th>\n",
       "      <th>Lineout_Win_Pct_Diff</th>\n",
       "      <th>Scrum_Win_Pct_Diff</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>151.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>151.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.402130</td>\n",
       "      <td>17.196314</td>\n",
       "      <td>2.491328</td>\n",
       "      <td>-1.993963</td>\n",
       "      <td>-0.644381</td>\n",
       "      <td>0.062044</td>\n",
       "      <td>5.298013</td>\n",
       "      <td>0.124614</td>\n",
       "      <td>-0.081126</td>\n",
       "      <td>0.562914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.750082</td>\n",
       "      <td>26.935639</td>\n",
       "      <td>45.526240</td>\n",
       "      <td>49.889728</td>\n",
       "      <td>59.542377</td>\n",
       "      <td>0.198595</td>\n",
       "      <td>27.780280</td>\n",
       "      <td>0.668788</td>\n",
       "      <td>0.637047</td>\n",
       "      <td>0.497677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-40.000000</td>\n",
       "      <td>-48.837209</td>\n",
       "      <td>-166.666667</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.491112</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>-27.500000</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.166253</td>\n",
       "      <td>16.129032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.795151</td>\n",
       "      <td>34.495192</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.181187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72.272727</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Poss_Time_Diff  Passes_Diff  Contestable_KO_Win_pct_Diff  \\\n",
       "count      151.000000   151.000000                   151.000000   \n",
       "mean        10.402130    17.196314                     2.491328   \n",
       "std         20.750082    26.935639                    45.526240   \n",
       "min        -40.000000   -48.837209                  -166.666667   \n",
       "25%         -3.491112     0.793651                   -27.500000   \n",
       "50%         11.166253    16.129032                     0.000000   \n",
       "75%         23.795151    34.495192                    33.333333   \n",
       "max         72.272727    90.909091                   133.333333   \n",
       "\n",
       "       PenFK_Against_Diff  RuckMaul_Diff  Ruck_Win_pct_Diff  Cards_diff  \\\n",
       "count          151.000000     151.000000         151.000000  151.000000   \n",
       "mean            -1.993963      -0.644381           0.062044    5.298013   \n",
       "std             49.889728      59.542377           0.198595   27.780280   \n",
       "min           -100.000000    -100.000000          -0.550000  -50.000000   \n",
       "25%            -33.333333     -33.333333          -0.083333    0.000000   \n",
       "50%              0.000000       0.000000           0.076923    0.000000   \n",
       "75%             33.333333      33.333333           0.181187    0.000000   \n",
       "max            100.000000     100.000000           0.875000  100.000000   \n",
       "\n",
       "       Lineout_Win_Pct_Diff  Scrum_Win_Pct_Diff      Result  \n",
       "count            151.000000          151.000000  151.000000  \n",
       "mean               0.124614           -0.081126    0.562914  \n",
       "std                0.668788            0.637047    0.497677  \n",
       "min               -1.000000           -1.000000    0.000000  \n",
       "25%                0.000000           -0.500000    0.000000  \n",
       "50%                0.000000            0.000000    1.000000  \n",
       "75%                0.750000            0.000000    1.000000  \n",
       "max                1.000000            1.000000    1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_data.head()\n",
    "#Check to insure 'Result' only contains 2 values (W, L)\n",
    "xg_data['Result'].describe()\n",
    "xg_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the neccessary libraries\n",
    "import xgboost\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "import pprint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('classifier', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the default parameters of the stages in our pipeline\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Once we have our pipeline with XGBoost classifier is set up, we can train it by invoking fit method.\n",
    "pipeline.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a210b4c88>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEWCAYAAACOv5f1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3XuYFOWZ9/HvPZwyMoqS4TCAnITAcHI4uJh3XRw2C4rgaeV1w+IqB4NKVlFRMy4rEd41ryaykZBEojGChmgWNUjU9bBIB+JKFoyAqIwk2IajQDwgw0QYvPePrsEGBqYHu/pA/T7X1RddT1V1/bqYvrv6qe56zN0REZFoKch2ABERyTwVfxGRCFLxFxGJIBV/EZEIUvEXEYkgFX8RkQhS8Rc5jJnNNbM7sp1DJEym7/lLuphZHGgDHEhq/oq7b/0Cj1kO/NzdO3yxdPnJzOYBm939X7OdRU4sOvKXdLvQ3YuSbsdd+NPBzBpnc/tfhJk1ynYGOXGp+EtGmNnZZvbfZvaRma0Jjuhr5403s7fN7BMz22hm1wTtzYH/BNqZ2Z7g1s7M5pnZvyWtX25mm5Om42b2LTNbC1SZWeNgvSfNbKeZvWtmNxwj68HHr31sM7vNzHaY2TYzu8TMLjCzd8zsAzP7l6R17zSzJ8zsl8Hz+b2ZnZk0v9TMYsF+eNPMLjpsu/eb2XNmVgVMBMYCtwXP/dfBchVm9sfg8d8ys0uTHmOcmf3WzO41sw+D5zoiaX5LM3vYzLYG8xclzRtlZquDbP9tZv1S/g+WvKPiL6Ezs/bAs8C/AS2BW4AnzaxVsMgOYBRwCjAe+L6ZDXD3KmAEsPU4PkmMAUYCpwKfAb8G1gDtga8BN5rZeSk+VlvgS8G604EHgSuAgcDfANPNrGvS8hcDC4Pn+gtgkZk1MbMmQY4XgdbA9cACM+uRtO4/AncBJwOPAAuA7wbP/cJgmT8G220BzAB+bmYlSY8xGKgEioHvAg+ZmQXzHgVOAnoHGb4PYGYDgJ8B1wBfBn4CLDazZinuI8kzKv6SbouCI8ePko4qrwCec/fn3P0zd38JWAVcAODuz7r7Hz3hNySK4998wRw/cPdN7l4NnAW0cveZ7r7P3TeSKOBfT/Gx9gN3uft+4HESRXW2u3/i7m8CbwLJR8mvufsTwfL/TuKN4+zgVgTcHeR4GXiGxBtVrafd/ZVgP/2lrjDuvtDdtwbL/BLYAPxV0iLvufuD7n4AmA+UAG2CN4gRwLXu/qG77w/2N8A3gJ+4++/c/YC7zwc+DTLLCShv+0MlZ13i7v91WFsn4P+a2YVJbU2ApQBBt8S3ga+QOCA5CXjjC+bYdNj225nZR0ltjYDlKT7Wn4NCClAd/Pt+0vxqEkX9iG27+2dBl1S72nnu/lnSsu+R+ERRV+46mdmVwM1A56CpiMQbUq3tSdvfGxz0F5H4JPKBu39Yx8N2Aq4ys+uT2pom5ZYTjIq/ZMIm4FF3/8bhM4JuhSeBK0kc9e4PPjHUdlPU9XW0KhJvELXa1rFM8nqbgHfdvfvxhD8Op9feMbMCoANQ2111upkVJL0BdATeSVr38Od7yLSZdSLxqeVrwKvufsDMVvP5/jqWTUBLMzvV3T+qY95d7n5XCo8jJwB1+0gm/By40MzOM7NGZval4ERqBxJHl82AnUBN8ClgeNK67wNfNrMWSW2rgQuCk5dtgRvr2f7/ALuDk8CFQYY+ZnZW2p7hoQaa2d8H3zS6kUT3yQrgdyTeuG4LzgGUAxeS6Eo6mveB5PMJzUm8IeyExMlyoE8qodx9G4kT6D82s9OCDEOC2Q8C15rZYEtobmYjzezkFJ+z5BkVfwmdu28icRL0X0gUrU3ArUCBu38C3AD8B/AhiROei5PWXQ88BmwMziO0I3HScg0QJ3F+4Jf1bP8AiSJbBrwL7AJ+SuKEaRieBv6BxPP5J+Dvg/71fcBFJPrddwE/Bq4MnuPRPAT0qj2H4u5vAbOAV0m8MfQFXmlAtn8icQ5jPYkT7TcCuPsqEv3+Pwxy/wEY14DHlTyjH3mJpJGZ3Ql0c/crsp1F5Fh05C8iEkEq/iIiEaRuHxGRCNKRv4hIBOXs9/xPPfVU79atW7ZjNFhVVRXNmzfPdowGUebMycfc+ZgZ8jN3OjK/9tpru9y9VX3L5Wzxb9OmDatWrcp2jAaLxWKUl5dnO0aDKHPm5GPufMwM+Zk7HZnN7L1UllO3j4hIBKn4i4hEkIq/iEgEqfiLiESQir+ISASp+IuIRJCKv4hIBKn4i4hEkIq/iEgEqfiLiESQir+ISASp+IuIRJCKv4hIBKn4i4hEkIq/iEgEqfiLiESQir+ISASp+IuIRJCKv4hIyCZMmEDr1q3p06fPwbY77riDfv36UVZWxvDhw9m6desh66xcuZJGjRrxxBNPhJIp1OJvZjeY2dtmtsDMfmBmfzCztWY2IMztiojkknHjxvH8888f0nbrrbeydu1aVq9ezahRo5g5c+bBeQcOHOBb3/oW5513XmiZwh7AfTIwAigFrge6A4OB+4N/j6p6/wE6Vzwbcrz0m9q3hnF5lluZMycfc+djZsh+7vjdIw/eHzJkCPF4/JD5p5xyysH7VVVVmNnB6Tlz5nDZZZexcuXK0PKFVvzNbC7QFVgMfAUY5+4OrDCzU82sxN23hbV9EZFcN23aNB555BFatGjB0qVLefPNN9myZQu/+tWvePnll0Mt/qF1+7j7tcBWYCjwErApafZmoH1Y2xYRyQd33XUXmzZtYuzYsfzwhz8E4MYbb+See+6hUaNGoW477G6fWlZHmx+xkNkkYBJAcXErpvetCTtX2rUpTHzczCfKnDn5mDsfM0P2c8disUOmt2/fTlVV1RHtAF26dOH222/nrLPO4re//S3Lly8H4OOPP+bpp59m/fr1nHPOOWnNl6nivxk4PWm6A4lPBYdw9weABwA6du3ms97IVLz0mdq3hnzLrcyZk4+58zEzZD93fGz5odPxOM2bN6e8PNG+YcMGunfvDiT6+AcOHEhRURHbtn3eGz5u3DhGjRrF6NGj054vU3tmMfDPZvY4iRO9H9fX31/YpBGVSSdM8kUsFjviPz3XKXPm5GPufMwMuZV7zJgxxGIxdu3aRYcOHZgxYwbPPfcclZWVFBQU0KlTJ+bOncuGDRsylilTxf854ALgD8BeYHyGtisiknWPPfbYEW0TJ048ou3w4j9v3rywIoVb/N29c9LkN8PcloiIpE6/8BURiSAVfxGRCFLxFxGJIBV/EZEIUvEXEYkgFX8RkQhS8RcRiSAVfxGRCFLxFxGJIBV/EZEIUvEXEYkgFX8RkQhS8RcRiSAVfxGRCFLxFxGJIBV/ETkuEyZMoHXr1vTp0+dg2wcffMCwYcPo3r07w4YN48MPPwRg/fr1fPWrX6VZs2bce++92YosScz9iHHU0/PAZjcA1wFvAe2AAcA0d0/pf75j125ecPnsULKFKdvjhh4PZc6cfMydnDmeNLTqsmXLKCoq4sorr2TdunUA3HbbbbRs2ZKKigruvvtuPvzwQ+655x527NjBe++9x6JFizjttNO45ZZbQs8di8UOjpebL9KR2cxec/dB9S0X5pH/ZBJDN14H3ADo7V7kBDJkyBBatmx5SNvTTz/NVVddBcBVV13FokWLAGjdujVnnXUWTZo0yXhOqVsoxd/M5gJdSQzcPtbdVwL7w9iWiOSO999/n5KSEgBKSkrYsWNHlhPJ0YTy+dPdrzWz84Gh7r4r1fXMbBIwCaC4uBXT+9aEES9UbQoTH5PziTJnTj7mTs4ci8UOmbd9+3aqqqoOttfU1ByyzOHT8XicwsLCIx4nDHv27MnIdtIpk5lzqvPR3R8AHoBEn3++9Y1C/vfp5ot8zAz5mfuQPv+x5YfMi8fjNG/e/GA/dfv27enRowclJSVs27aNdu3aHdKHHYvFKCoqykhffFT7/FOVs3+FhU0aUZl0cilfxGKxI14guU6ZMycfczck80UXXcT8+fOpqKhg/vz5XHzxxeGGk+OWs8VfRHLbmDFjiMVi7Nq1iw4dOjBjxgwqKiq4/PLLeeihh+jYsSMLFy4EEt1DgwYNYvfu3RQUFHDffffx1ltvccopp2T5WURX6MXfzNoCq4BTgM/M7Eagl7vvDnvbIhKexx57rM72JUuWHNHWtm1bNm/eHHYkaYDQir+7d06a7BDWdkREpOH0C18RkQhS8RcRiSAVfxGRCFLxFxGJIBV/EZEIUvEXEYkgFX8RkQhS8RcRiSAVfxGRCFLxFxGJIBV/EZEIUvEXEYkgFX8RkQhS8RcRiSAVf5E88f3vf5/evXvTp08fxowZw1/+8hfGjRtHly5dKCsro6ysjNWrV2c7puSJ0K7nb2Y3ANcBPYE3guY9wHXuvqa+9av3H6BzxbNhxQvN1L41jMuz3MqcOQ3JHU8axnTLli384Ac/4K233qKwsJDLL7+cxx9/HIDvfe97jB49OpS8cuIKcySvycAIoAR4290/NLMRJAZoHxzidkVOSDU1NVRXV9OkSRP27t1Lu3btsh1J8lgo3T5mNhfoCiwGBrv7h8GsFWhUL5EGa9++PbfccgsdO3akpKSEFi1aMHz4cACmTZtGv379uOmmm/j000+znFTyhbl7OA9sFgcGufuupLZbgJ7ufvVR1pkETAIoLm41cPp9D4aSLUxtCuH96mynaBhlzpyG5O7bvsXB+5988gnf/va3mT59OkVFRdx5552ce+65DBgwgJYtW7J//35mzZpFu3btuOqqq9Kaec+ePRQVFaX1MTMhH3OnI/PQoUNfc/dB9S0X+gDutcxsKDAROOdoy7j7AyS6hejYtZvPeiNj8dJmat8a8i23MmdOQ3LHx5YfvL9w4UL69+/PJZdcAsDWrVtZsWIFl1122cFlmjZtyr333kt5eTnpFIvF0v6YmZCPuTOZOSOvHjPrB/wUGOHuf05lncImjahMOuGVL2Kx2CEv2nygzJlzvLk7duzIihUr2Lt3L4WFhSxZsoRBgwaxbds2SkpKcHcWLVpEnz590h9aTkihF38z6wg8BfyTu78T9vZETkSDBw9m9OjRDBgwgMaNG9O/f38mTZrEiBEj2LlzJ+5OWVkZc+fOzXZUyROZOPKfDnwZ+LGZAdSk0h8lIoeaMWMGM2bMOKTt5ZdfzlIayXehFX937xzcvTq4iYhIjtAvfEVEIkjFX0QkglT8RUQiSMVfRCSCVPxFRCJIxV9EJIJU/EVEIkjFX0QkglT8RUQiSMVfRCSCVPxFRCKowcXfzE4LLtEsIiJ5KqXib2YxMzvFzFoCa4CHzezfw40mIiJhSfXIv4W77wb+HnjY3QcCfxdeLBERCVOqxb+xmZUAlwPPhJhHJKM++ugjRo8eTc+ePSktLeXVV18FYM6cOfTo0YPevXtz2223ZTmlSPqlej3/mcALwCvuvtLMugIb6lvJzG4ArgPaApuAz4Aa4EZ3/+3xRRZJnylTpnD++efzxBNPsG/fPvbu3cvSpUt5+umnWbt2Lc2aNWPHjh3ZjimSdikVf3dfCCxMmt4IXHb0NQ6aDIwAdgJV7u7ByeL/AHoea8Xq/QfoXPFsKvFyytS+NYzLs9xRyhxPGhd69+7dLFu2jHnz5gGJAdCbNm3K/fffT0VFBc2aNQOgdevWackskktSPeH7FTNbYmbrgul+Zvav9awzF+gKLAa+4e4ezGoO+FFXFMmQjRs30qpVK8aPH0///v25+uqrqaqq4p133mH58uUMHjyYc889l5UrV2Y7qkja2ec1+RgLmf0GuBX4ibv3D9rWuXufetaLA4PcfZeZXQr8f6A1MNLdX61j+UnAJIDi4lYDp9/3YAOfTva1KYT3q7OdomGilLlv+xYH71dWVjJ58mTmzJlDr169mDNnDs2bN2f58uX079+f66+/nvXr1zNz5kx+8YtfEIxB/YXs2bOHoqKiL/w4mZSPmSE/c6cj89ChQ19LZZz0VIv/Snc/y8xeTyr+q929rJ714gTFP6ltCDDd3Y/5baGOXbt5weWz682Wa6b2rWHWG6ENjRyKKGVO7vbZvn07Z599NvF4HIDly5dz9913c+DAASoqKigvLwfgjDPOYMWKFbRq1eoL547FYgcfN1/kY2bIz9zpyGxmKRX/VF89u8zsDILuGjMbDWw7nmDuvszMzjCz4uQ3hcMVNmlEZdILNV/EYjHiY8uzHaNBopq5bdu2nH766VRWVtKjRw+WLFlCr169OOOMM3j55ZcpLy/nnXfeYd++fRQXF6cnuEiOSLX4fxN4AOhpZluAd4GxqW7EzLoBfwxO+A4AmgJ/bmhYkXSbM2cOY8eOZd++fXTt2pWHH36Y5s2bM2HCBPr06UPTpk2ZP39+Wrp8RHJJvcXfzApIdN38nZk1Bwrc/ZMGbucy4Eoz2w9UA//gqfQ3iYSsrKyMVatWHdH+85//PAtpRDKn3uLv7p+Z2T8D/+HuVQ15cHfvHNy9J7iJiEgOSPUXvi+Z2S1mdrqZtay9hZpMRERCk2qf/4Tg328mtTmJ7/GLiEieSfUXvl3CDiIiIpmTUvE3syvranf3R9IbR0REMiHVbp+zku5/Cfga8HtAxV9EJA+l2u1zffK0mbUAHg0lkYiIhO54x/DdC3RPZxAREcmcVPv8f83nV+IsAHqRdIlnERHJL6n2+d+bdL8GeM/dN4eQR0REMiDVbp8L3P03we0Vd99sZvrFrohInkq1+A+ro21EOoOIiEjmHLPbx8yuIzEUY1czW5s062TglTCDiYhIeOrr8/8F8J8kRuCqSGr/xN0/CC2ViIiE6pjF390/Bj4GxgCYWWsSP/IqMrMid/9T+BFFRCTdUh3A/UIz20BiEJffAHESnwhEct5HH33E6NGj6dmzJ6Wlpbz66qvccccd9OvXj7KyMoYPH87WrVuzHVMko1I94ftvwNnAO8FF3r5GPX3+ZnaDmb1tZlvM7GMzWx3cpn/BzCINMmXKFM4//3zWr1/PmjVrKC0t5dZbb2Xt2rWsXr2aUaNGMXPmzGzHFMmoVL/nv9/d/2xmBWZW4O5LU/iq52QS3wjqBNzi7qMaEqx6/wE6VzzbkFVywtS+NYzLs9wnWubkQdp3797NsmXLmDdvHgBNmzaladOmhyxfVVWlYRolclIt/h+ZWRGwHFhgZjtI/NirTmY2l8S1/hcDP/vCKUWO08aNG2nVqhXjx49nzZo1DBw4kNmzZ9O8eXOmTZvGI488QosWLVi6dGm2o4pklKUylG4wdm81iW6isUALYIG7H3UQdjOLA4OAPsCTwGZgK4lPAW8eZZ1JwCSA4uJWA6ff92BDnktOaFMI71dnO0XDnGiZ+7ZvcfB+ZWUlkydPZs6cOfTq1Ys5c+YcHKC91oIFC9i3bx/jx48POzZ79uyhqKgo9O2kUz5mhvzMnY7MQ4cOfc3dB9W3XErFH8DMOgHd3f2/zOwkoNGxBnJPKv77gM/cfY+ZXQDMdvd6LwrXsWs3L7h8dkrZcsnUvjXMeiPVD1S54UTLnNzts337ds4++2zi8TgAy5cv5+677+bZZz/vMnrvvfcYOXIk69atCzUzQCwWo7y8PPTtpFM+Zob8zJ2OzGaWUvFP9ds+3wCeAH4SNLUHFqWyrrvvdvc9wf3ngCZmVpzKuiJfVNu2bTn99NOprKwEYMmSJfTq1YsNGzYcXGbx4sX07NkzWxFFsiLVw71vAn8F/A7A3TcE3/mvl5m1Bd53dzezvyLxhnPU7qJahU0aUZl0BJcvYrEY8bHl2Y7RICd65jlz5jB27Fj27dtH165defjhh7n66quprKykoKCATp06MXfu3HADi+SYVIv/p+6+r/YbEWbWmM8v8Vyf0cB1ZlZD4rzB1z3VviaRNCgrK2PVqlWHtD355JNZSiOSG1It/r8xs38BCs1sGImvcf76WCu4e+fg7g+Dm4iI5IhUf+RVAewE3gCuAZ4D/jWsUCIiEq76rurZ0d3/5O6fAQ8GNxERyXP1Hfkf/EaPmamTVETkBFFf8U/+zXvXMIOIiEjm1Ff8/Sj3RUQkj9X3bZ8zzWw3iU8AhcF9gml391NCTSciIqGobzCXRpkKIiIimZPqVz1FROQEouIvIhJBKv4iIhGk4i8iEkEq/iIiEaTiLyISQSr+IiIRpOKfBZs2bWLo0KGUlpbSu3dvZs9ODFd5xx130K9fP8rKyhg+fDhbt27NclIROVGFWvzN7AYze9vMFgTTZ5nZATMbHeZ2c13jxo2ZNWsWb7/9NitWrOBHP/oRb731Frfeeitr165l9erVjBo1ipkzZ2Y7qoicoMIetXsyMMLd3zWzRsA9wAuprFi9/wCdK56tf8EcM7VvDePqyJ08qHhJSQklJSUAnHzyyZSWlrJlyxZ69ep1cJmqqipqR04TEUm30Iq/mc0lcSXQxWb2MxIXhnsSOCusbeajeDzO66+/zuDBgwGYNm0ajzzyCC1atGDp0qVZTiciJyoLczhdM4sDg4BmwC+AvwUeAp5x9yfqWH4SMAmguLjVwOn35d/YMW0K4f3qI9v7tm9xRFt1dTVTpkzhiiuuYMiQIYfMW7BgAfv27WP8+PFhRT1oz549FBUVhb6ddMrHzJCfufMxM+Rn7nRkHjp06GvuPqi+5cLu9ql1H/Atdz9wrK4Md38AeACgY9duPuuNTMVLn6l9a6grd3xs+SHT+/fvZ9SoUVx77bXcfPPNRyzfpUsXRo4cyfz588OKelAsFqO8vLze5XJJPmaG/Mydj5khP3NnMnOmqusg4PGg8BcDF5hZjbsvOvZqJyZ3Z+LEiZSWlh5S+Dds2ED37t0BWLx4MT179sxWRBE5wWWk+Lt7l9r7ZjaPRLfPMQt/YZNGVCadJM0XsVjsiKP8w73yyis8+uij9O3bl7KyMgC+853v8NBDD1FZWUlBQQGdOnVi7ty5GUgsIlGUf/0qJ4BzzjmHus61XHDBBVlIIyJRFGrxd/fOdbSNC3ObIiJSP/3CV0QkglT8RUQiSMVfRCSCVPxFRCJIxV9EJIJU/EVEIkjFX0QkglT8RUQiSMVfRCSCVPxFRCJIxV9EJIJU/EVEIkjFX0QkglT8RUQiSMU/AzZt2sTQoUMpLS2ld+/ezJ49G4CFCxfSu3dvCgoKWLVqVZZTikiUhHY9fzO7AbgO6AhsSNpeKdDK3T8Ia9u5pnHjxsyaNYsBAwbwySefMHDgQIYNG0afPn146qmnuOaaa7IdUUQiJszBXCYDI9z93doGM7sQuCmVwl+9/wCdK54NMV44pvatYVzFs8SThqAsKSmhpKQEgJNPPpnS0lK2bNnCsGHDshVTRCIulG4fM5sLdAUWm9lNSbPGAI+Fsc18EY/Hef311xk8eHC2o4hIhFldY8mm5YHN4sAgd98VTJ8EbAa6He3I38wmAZMAiotbDZx+34OhZAtTm0J4vxr6tm9xxLzq6mqmTJnCFVdcwZAhQw6233jjjVx33XX06NEjk1EP2rNnD0VFRVnZ9vHKx8yQn7nzMTPkZ+50ZB46dOhr7j6ovuUyOYD7hcArx+rycfcHgAcAOnbt5rPeyL/x5af2rWHWG42Jjy0/pH3//v2MGjWKa6+9lptvvvmQeaeeeioDBw5k0KB6/79CEYvFKC8vz8q2j1c+Zob8zJ2PmSE/c2cycya/7fN1Itrl4+5MnDiR0tLSIwq/iEg2ZOTQ2sxaAOcCV6S6TmGTRlQmnTTNF7FY7Iij/ldeeYVHH32Uvn37UlZWBsB3vvMdPv30U66//np27tzJyJEjKSsr44UXXshCahGJmkz1q1wKvOjuVRnaXk4555xzONq5lUsvvTTDaUREQiz+7t456f48YF5Y2xIRkYbRL3xFRCJIxV9EJIJU/EVEIkjFX0QkglT8RUQiSMVfRCSCVPxFRCJIxV9EJIJU/EVEIkjFX0QkglT8RUQiSMVfRCSCVPxFRCJIxV9EJIJU/FMwYcIEWrduTZ8+fY6Yd++992Jm7Nq1KwvJRESOT6jF38xuMLO3zexXZvZrM1tjZm+a2fgwt5tu48aN4/nnnz+ifdOmTbz00kt07NgxC6lERI5f2CN5TQZGAGOAFu5+oZm1AirNbIG77zvaitX7D9C54tmQ4x1dPGkIySFDhhCPx49Y5qabbuK73/0uF198cQaTiYh8caEd+ZvZXKArsBhw4GQzM6AI+ACoCWvbmbB48WLat2/PmWeeme0oIiINFuYwjtea2fnAUOBTEm8CW4GTgX9w98/C2nbY9u7dy1133cWLL76Y7SgiIsfFjjaweFoe3CwODALKgb8GbgbOAF4CznT33YctPwmYBFBc3Grg9PseDC1bffq2b3HI9Pbt27n99tt5+OGH2bhxI1OnTqVZs2YA7Ny5k+LiYu6//36aNm1KUVFRNiIftz179ihzhuRj7nzMDPmZOx2Zhw4d+pq7D6pvuUwV//nA3e6+PGh/Gahw9/852rodu3bzgstnh5atPsl9/gDxeJxRo0axbt26I5bt3Lkzq1atori4mFgsRnl5eYZSpocyZ04+5s7HzJCfudOR2cxSKv5hn/Ct9Sfga8ByM2sD9AA2HmuFwiaNqDysAGfLmDFjiMVi7Nq1iw4dOjBjxgwmTpyY7VgiIsctU8X//wHzzOwNwIBvuXvefDH+scceO+b8ur4JJCKSy0It/u7eOWlyeJjbEhGR1OkXviIiEaTiLyISQSr+IiIRpOIvIhJBKv4iIhGk4i8iEkEq/iIiEaTiLyISQSr+IiIRpOIvIhJBKv4iIhGk4i8iEkEq/iIiEaTiLyISQSr+IiIRpOIvIhJBKv4iIhGk4i8iEkEq/iIiEWTunu0MdTKzT4DKbOc4DsVA3gxOH1DmzMnH3PmYGfIzdzoyd3L3VvUtFOoA7l9QpbsPynaIhjKzVfmWW5kzJx9z52NmyM/cmcysbh8RkQhS8RcRiaBcLv4PZDvAccrH3MqcOfmYOx8zQ37mzljmnD3hKyIi4cnlI38REQmJir+ISATlZPE3s/PNrNLM/mBmFdnOUxczO93MlprZ22b2pplNCdpbmtlLZrYh+Pe0bGc9nJk1MrPXzeyZYLqLmf0uyPxLM2ua7YyHM7NTzewJM1sf7PPmLt8QAAAF5ElEQVSv5vq+NrObgr+NdWb2mJl9KRf3tZn9zMx2mNm6pLY6960l/CB4ba41swE5lPl7wd/HWjP7lZmdmjTv9iBzpZmdl43MQY4jcifNu8XM3MyKg+lQ93XOFX8zawT8CBgB9ALGmFmv7KaqUw0w1d1LgbOBbwY5K4Al7t4dWBJM55opwNtJ0/cA3w8yfwhMzEqqY5sNPO/uPYEzSeTP2X1tZu2BG4BB7t4HaAR8ndzc1/OA8w9rO9q+HQF0D26TgPszlPFw8zgy80tAH3fvB7wD3A4QvC6/DvQO1vlxUGeyYR5H5sbMTgeGAX9Kag53X7t7Tt2ArwIvJE3fDtye7Vwp5H46+M+rBEqCthISP1bLer6knB1IvJj/FngGMBK/KGxc1/7PhRtwCvAuwRcUktpzdl8D7YFNQEsSP6Z8BjgvV/c10BlYV9++BX4CjKlruWxnPmzepcCC4P4hNQR4AfhqruzroO0JEgc1caA4E/s65478+fxFU2tz0JazzKwz0B/4HdDG3bcBBP+2zl6yOt0H3AZ8Fkx/GfjI3WuC6Vzc312BncDDQXfVT82sOTm8r919C3AviSO5bcDHwGvk/r6udbR9my+vzwnAfwb3czqzmV0EbHH3NYfNCjV3LhZ/q6MtZ7+PamZFwJPAje6+O9t5jsXMRgE73P215OY6Fs21/d0YGADc7+79gSpyqIunLkEf+cVAF6Ad0JzEx/jD5dq+rk/O/72Y2TQS3bILapvqWCwnMpvZScA0YHpds+toS1vuXCz+m4HTk6Y7AFuzlOWYzKwJicK/wN2fCprfN7OSYH4JsCNb+erw18BFZhYHHifR9XMfcKqZ1V7nKRf392Zgs7v/Lph+gsSbQS7v678D3nX3ne6+H3gK+D/k/r6udbR9m9OvTzO7ChgFjPWgr4TcznwGiQOENcHrsgPwezNrS8i5c7H4rwS6B9+KaEriRM3iLGc6gpkZ8BDwtrv/e9KsxcBVwf2rSJwLyAnufru7d3D3ziT268vuPhZYCowOFsupzADuvh3YZGY9gqavAW+Rw/uaRHfP2WZ2UvC3Ups5p/d1kqPt28XAlcE3Uc4GPq7tHso2Mzsf+BZwkbvvTZq1GPi6mTUzsy4kTqD+TzYyHs7d33D31u7eOXhdbgYGBH/z4e7rbJ30qOeEyAUkztb/EZiW7TxHyXgOiY9ga4HVwe0CEn3oS4ANwb8ts531KPnLgWeC+11JvBj+ACwEmmU7Xx15y4BVwf5eBJyW6/samAGsB9YBjwLNcnFfA4+ROC+xn0TxmXi0fUuiK+JHwWvzDRLfZsqVzH8g0Ude+3qcm7T8tCBzJTAil/b1YfPjfH7CN9R9rcs7iIhEUC52+4iISMhU/EVEIkjFX0QkglT8RUQiSMVfRCSCcnkAd5FQmNkBEl+dq3WJu8ezFEckK/RVT4kcM9vj7kUZ3F5j//x6PiI5Qd0+IocxsxIzW2Zmq4Nr8f9N0H6+mf3ezNaY2ZKgraWZLQqut77CzPoF7Xea2QNm9iLwiCXGUPiema0Mlr0mi09RRN0+EkmFZrY6uP+uu1962Px/JHGp5buC676fZGatgAeBIe7+rpm1DJadAbzu7peY2d8Cj5D4NTLAQOAcd682s0kkfp5/lpk1A14xsxfd/d0wn6jI0aj4SxRVu3vZMeavBH4WXLhvkbuvNrNyYFltsXb3D4JlzwEuC9peNrMvm1mLYN5id68O7g8H+plZ7XV9WpC4xoyKv2SFir/IYdx9mZkNAUYCj5rZ94CPqPtyuse67G7VYctd7+4vpDWsyHFSn7/IYcysE4lxDx4kceXWAcCrwLnBVSFJ6vZZBowN2sqBXV73uA4vANcFnyYws68EA9KIZIWO/EWOVA7camb7gT3Ale6+M+i3f8rMCkhc334YcCeJEcbWAnv5/DLIh/spieH7fh9c4nkncEmYT0LkWPRVTxGRCFK3j4hIBKn4i4hEkIq/iEgEqfiLiESQir+ISASp+IuIRJCKv4hIBP0v8BgYjzuj4f0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgboost.plot_importance(pipeline.steps[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions on test data and evaluate the model\n",
    "y_pred = pipeline.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.35%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tune our model now to achieve better accuracy by using grid search and cross validation.\n",
    "\n",
    "XGBoost hyperparameters:\n",
    "\n",
    "learning_rate (default=0.1): Boosting learning rate (xgb’s “eta”).  \n",
    "n_estimators (default=100): Number of boosted trees to fit.  \n",
    "max_depth (default=3): Maximum tree depth for base learners.  \n",
    "objective (default='binary:logistic'): Specify the learning task and the corresponding learning objective or a custom objective function to be used.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create our XGBoost pipeline and setup parameter space.\n",
    "\n",
    "pipeline_gs = Pipeline([('scaler', StandardScaler()), ('classifier', XGBClassifier())])\n",
    "parameters = {'classifier__learning_rate': [0.01, 0.03], 'classifier__n_estimators': [50, 200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the best parameters with GridSearchCV. \n",
    "# You can use estimator.get_params().keys() to see the available hyperparameters for search.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(pipeline_gs, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child...       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'classifier__learning_rate': [0.01, 0.03], 'classifier__n_estimators': [50, 200]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/admin/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00911999, 0.02239116, 0.00535727, 0.02154072]),\n",
       " 'std_fit_time': array([1.54628495e-03, 3.10490369e-03, 2.57433190e-05, 3.16432705e-04]),\n",
       " 'mean_score_time': array([0.00093492, 0.00089614, 0.00050926, 0.00144498]),\n",
       " 'std_score_time': array([1.67956408e-04, 1.82184281e-04, 1.24891289e-05, 1.13082870e-04]),\n",
       " 'param_classifier__learning_rate': masked_array(data=[0.01, 0.01, 0.03, 0.03],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__n_estimators': masked_array(data=[50, 200, 50, 200],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__learning_rate': 0.01,\n",
       "   'classifier__n_estimators': 50},\n",
       "  {'classifier__learning_rate': 0.01, 'classifier__n_estimators': 200},\n",
       "  {'classifier__learning_rate': 0.03, 'classifier__n_estimators': 50},\n",
       "  {'classifier__learning_rate': 0.03, 'classifier__n_estimators': 200}],\n",
       " 'split0_test_score': array([0.54285714, 0.57142857, 0.6       , 0.6       ]),\n",
       " 'split1_test_score': array([0.62857143, 0.62857143, 0.62857143, 0.62857143]),\n",
       " 'split2_test_score': array([0.6       , 0.65714286, 0.65714286, 0.65714286]),\n",
       " 'mean_test_score': array([0.59047619, 0.61904762, 0.62857143, 0.62857143]),\n",
       " 'std_test_score': array([0.03563483, 0.03563483, 0.02332847, 0.02332847]),\n",
       " 'rank_test_score': array([4, 3, 1, 1], dtype=int32),\n",
       " 'split0_train_score': array([0.82857143, 0.87142857, 0.85714286, 0.97142857]),\n",
       " 'split1_train_score': array([0.88571429, 0.9       , 0.9       , 0.95714286]),\n",
       " 'split2_train_score': array([0.82857143, 0.91428571, 0.92857143, 0.98571429]),\n",
       " 'mean_train_score': array([0.84761905, 0.8952381 , 0.8952381 , 0.97142857]),\n",
       " 'std_train_score': array([0.0269374 , 0.01781742, 0.02935435, 0.01166424])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See the performance result of all parameter combinations including the best parameter combination \n",
    "#based on model performance from grid search scores\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.6285714285714286\n",
      "Best parameter set: {'classifier__learning_rate': 0.03, 'classifier__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Best score and parameter set\n",
    "print(\"Best score: %s\" % (clf.best_score_))\n",
    "print(\"Best parameter set: %s\" % (clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 39.13%\n"
     ]
    }
   ],
   "source": [
    "#Get the accuracy of best parameter combination on test set.\n",
    "\n",
    "y_pred = clf.predict(X_test.values)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
