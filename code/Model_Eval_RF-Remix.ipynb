{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation - Random Forest Models on Diff Data\n",
    "USA World Series Results,\n",
    "Run on \"Diff\" data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @To Do\n",
    "\n",
    "- [ ] Randomize data and rebuild model\n",
    "    * Limit to very simple tuning, so as not to overfit\n",
    "    * n_estimators = 100 to 3-400\n",
    "    * 5-fold or 6-fold CV\n",
    "    * max_features = 5 or 6\n",
    "- [ ] Merge new data from validation set into full data set\n",
    "- [ ] Explore relationship between Posession Time + Attacking Rucks + Passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Opp</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Poss_Time_Diff</th>\n",
       "      <th>Score_Diff</th>\n",
       "      <th>Conv_Diff</th>\n",
       "      <th>Tries_Diff</th>\n",
       "      <th>Passes_Diff</th>\n",
       "      <th>Contestable_KO_Win_pct_Diff</th>\n",
       "      <th>PenFK_Against_Diff</th>\n",
       "      <th>RuckMaul_Diff</th>\n",
       "      <th>...</th>\n",
       "      <th>-99 : -75</th>\n",
       "      <th>-74 : -25</th>\n",
       "      <th>-24 : -1</th>\n",
       "      <th>0 : 25</th>\n",
       "      <th>26 : 50</th>\n",
       "      <th>51 : 75</th>\n",
       "      <th>76 : 100</th>\n",
       "      <th>101 : 125</th>\n",
       "      <th>126 : 150</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>2015_Cape_Town</td>\n",
       "      <td>13.966480</td>\n",
       "      <td>-10.638298</td>\n",
       "      <td>-14.285714</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>25.925926</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WALES</td>\n",
       "      <td>2015_Cape_Town</td>\n",
       "      <td>7.471264</td>\n",
       "      <td>15.555556</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>27.868852</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KENYA</td>\n",
       "      <td>2015_Cape_Town</td>\n",
       "      <td>-33.136095</td>\n",
       "      <td>-44.444444</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-10.638298</td>\n",
       "      <td>-16.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW ZEALAND</td>\n",
       "      <td>2015_Cape_Town</td>\n",
       "      <td>51.758794</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.119403</td>\n",
       "      <td>-75.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FIJI</td>\n",
       "      <td>2015_Cape_Town</td>\n",
       "      <td>12.880562</td>\n",
       "      <td>-20.833333</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Opp      Tournament  Poss_Time_Diff  Score_Diff  Conv_Diff  \\\n",
       "0    AUSTRALIA  2015_Cape_Town       13.966480  -10.638298 -14.285714   \n",
       "1        WALES  2015_Cape_Town        7.471264   15.555556  14.285714   \n",
       "2        KENYA  2015_Cape_Town      -33.136095  -44.444444 -33.333333   \n",
       "3  NEW ZEALAND  2015_Cape_Town       51.758794   33.333333  33.333333   \n",
       "4         FIJI  2015_Cape_Town       12.880562  -20.833333 -25.000000   \n",
       "\n",
       "   Tries_Diff  Passes_Diff  Contestable_KO_Win_pct_Diff  PenFK_Against_Diff  \\\n",
       "0    0.250000    25.925926                   -50.000000            0.000000   \n",
       "1    0.083333    27.868852                    25.000000          -20.000000   \n",
       "2   -0.750000   -10.638298                   -16.666667           66.666667   \n",
       "3    0.000000    76.119403                   -75.000000          -50.000000   \n",
       "4    0.266667    38.461538                   -66.666667          -33.333333   \n",
       "\n",
       "   RuckMaul_Diff   ...    -99 : -75  -74 : -25  -24 : -1  0 : 25  26 : 50  \\\n",
       "0       0.000000   ...          0.0      -12.5       0.0     0.0      0.0   \n",
       "1    -100.000000   ...          0.0        0.0       0.0    12.5      0.0   \n",
       "2      60.000000   ...          0.0        0.0      -5.0     0.0      0.0   \n",
       "3    -100.000000   ...        -37.5        0.0       0.0     0.0      0.0   \n",
       "4     -33.333333   ...          0.0      -12.5       0.0     0.0      0.0   \n",
       "\n",
       "   51 : 75  76 : 100  101 : 125  126 : 150  Result  \n",
       "0      0.0       0.0        0.0        0.0       0  \n",
       "1      0.0       0.0        0.0        0.0       1  \n",
       "2      0.0       0.0        0.0        0.0       0  \n",
       "3      0.0       0.0        0.0        0.0       1  \n",
       "4      0.0       0.0        0.0        0.0       0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Data - USA's differential data\n",
    "df = pd.read_csv('../data/output/new_features_diffdata.csv')\n",
    "df.head()\n",
    "\n",
    "#Import validation data\n",
    "#valdf = pd.read_csv('../data/output/new_features_diffdata_validate.csv')\n",
    "#valdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle dataframes before running model to prevent overfitting\n",
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)\n",
    "#shuffle validation set\n",
    "#valdf = shuffle(valdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Opp',\n",
       " 'Tournament',\n",
       " 'Poss_Time_Diff',\n",
       " 'Score_Diff',\n",
       " 'Conv_Diff',\n",
       " 'Tries_Diff',\n",
       " 'Passes_Diff',\n",
       " 'Contestable_KO_Win_pct_Diff',\n",
       " 'PenFK_Against_Diff',\n",
       " 'RuckMaul_Diff',\n",
       " 'Ruck_Win_pct_Diff',\n",
       " 'Cards_diff',\n",
       " 'Lineout_Win_Pct_Diff',\n",
       " 'Scrum_Win_Pct_Diff',\n",
       " '-175 : -150',\n",
       " '-149 : -125',\n",
       " '-124 : -100',\n",
       " '-99 : -75',\n",
       " '-74 : -25',\n",
       " '-24 : -1',\n",
       " '0 : 25',\n",
       " '26 : 50',\n",
       " '51 : 75',\n",
       " '76 : 100',\n",
       " '101 : 125',\n",
       " '126 : 150',\n",
       " 'Result']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Diagnostic\n",
    "#df.info()\n",
    "list(df.columns)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of features to drop that are unneccessary or will bias the prediction\n",
    "droplist = ['Opp', 'Score_Diff', 'Tries_Diff','Tournament', 'Conv_Diff','-175 : -150', '-149 : -125','-124 : -100', '-99 : -75', '-74 : -25','-24 : -1','0 : 25','26 : 50','51 : 75','76 : 100','101 : 125','126 : 150']\n",
    "\n",
    "rf_data = df.drop((droplist), axis=1)\n",
    "\n",
    "#Drop rows with Result == \"2\" (Ties). This label messes up classification models\n",
    "rf_data.drop(rf_data[rf_data.Result == 2].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#rf_data.head()\n",
    "#Check to insure 'Result' only contains 2 values (W, L)\n",
    "#rf_data['Result'].describe()\n",
    "#rf_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(rf_data.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull out the variable we're trying to predict: 'Result'\n",
    "X = rf_data.drop('Result',axis=1)\n",
    "y = rf_data['Result']\n",
    "#X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "*Commented out, because if using standard scaler in a pipeline, it does it for you - see notes below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train/test/validate sets\n",
    "#OR, keep as is and use new data for validate\n",
    "#156 rows in original dataframe\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">## NOTE:</span>  \n",
    "https://stackoverflow.com/questions/51459406/apply-standardscaler-in-pipeline-in-scikit-learn-sklearn\n",
    "\n",
    "When you use the StandardScaler as a step inside a Pipeline then scikit-learn will internally do the job for you.\n",
    "\n",
    "What happens can be discribed as follows:  \n",
    "\n",
    "* Step 0: The data are split into TRAINING data and TEST data according to the cv parameter that you specified in the GridSearchCV.\n",
    "* Step 1: the scaler is fitted on the TRAINING data\n",
    "* Step 2: the scaler transforms TRAINING data\n",
    "* Step 3: the models are fitted/trained using the transformed TRAINING data\n",
    "* Step 4: the scaler is used to transform the TEST data\n",
    "* Step 5: the trained models predict using the transformed TEST data\n",
    "\n",
    "***Note:*** You should be using grid.fit(X, y) and NOT grid.fit(X_train, y_train) because the GridSearchCV will automatically split the data into training and testing data (this happen internally).\n",
    "\n",
    "Your code should look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>pipe = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('reduce_dims', PCA(n_components=4)),\n",
    "        ('clf', SVC(kernel = 'linear', C = 1))])\n",
    "\n",
    "param_grid = dict(reduce_dims__n_components=[4,6,8],\n",
    "                  clf__C=np.logspace(-4, 1, 6),\n",
    "                  clf__kernel=['rbf','linear'])\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=1, verbose=2, scoring= 'accuracy')\n",
    "grid.fit(X, y)\n",
    "print(grid.best_score_)\n",
    "print(grid.cv_results_)</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you run this code (when you call **grid.fit(X, y)**), you can access the outcome of the grid search in the result object returned from grid.fit(). The **best_score_ member** provides access to the best score observed during the optimization procedure and the **best_params_** describes the combination of parameters that achieved the best results.\n",
    "\n",
    "**IMPORTANT:** if you want to keep a validation dataset of the original dataset use this:\n",
    "\n",
    "<code>X_for_gridsearch, X_future_validation, y_for_gridsearch, y_future_validation \n",
    "    = train_test_split(X, y, test_size=0.15, random_state=1)</code>\n",
    "    \n",
    "Then use:\n",
    "\n",
    "<code>grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=1, verbose=2, scoring= 'accuracy')\n",
    "grid.fit(X_for_gridsearch, y_for_gridsearch)</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a transformation pipeline\n",
    "Pipeline with Scaling and Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# Standardize data (0 mean, 1 stdev)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#create the pipeline\n",
    "scale_pipeline = Pipeline([\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# fit the pipeline\n",
    "#scale_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Pipeline test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pipeline test accuracy\n",
    "#print('Test accuracy: %.3f' % scale_pipeline.score(X_test, y_test))\n",
    "\n",
    "# Pipeline estimator params; estimator is stored as step 2 ([1]), second item ([1])\n",
    "#print('\\nModel hyperparameters:\\n', scale_pipeline.steps[1][1].get_params())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Results from Pipeline test above:\n",
    "\n",
    "Test accuracy: 0.565\n",
    "\n",
    "Model hyperparameters:\n",
    " {'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search with Cross Validation\n",
    "Random search allowed us to narrow down the range for each hyperparameter. Now that we know where to concentrate our search, we can explicitly specify every combination of settings to try. We do this with GridSearchCV, a method that, instead of sampling randomly from a distribution, evaluates all combinations we define.  \n",
    "\n",
    "### Hyperparameters\n",
    "* n_estimators = number of trees in the foreset\n",
    "* max_features = max number of features considered for splitting a node\n",
    "* max_depth = max number of levels in each decision tree\n",
    "* min_samples_split = min number of data points placed in a node before the node is split\n",
    "* min_samples_leaf = min number of data points allowed in a leaf node\n",
    "* bootstrap = method for sampling data points (with or without replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'classifier__bootstrap': [True, False],\n",
    "    'classifier__max_depth': [60, 80, 100],\n",
    "    'classifier__max_features': ['auto', 4, 5, 6],\n",
    "    'classifier__min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "    'classifier__min_samples_split': [2, 5, 8, 10, 12],\n",
    "    'classifier__n_estimators': [10, 20, 40, 60, 100], # [100, 200, 300, 400]\n",
    "    'classifier__criterion': ['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "If ***not*** using pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Fit RF Classifier model\n",
    "#rf = RandomForestClassifier(random_state=101)\n",
    "\n",
    "#from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "#print('Default Parameters currently in use:\\n')\n",
    "#pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute gridsearch and get best score\n",
    "rf_grid = GridSearchCV(scale_pipeline, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring= 'accuracy')\n",
    "\n",
    "# fit on ALL grid.fit(X, y) and NOT grid.fit(X_train, y_train) because the GridSearchCV will automatically \n",
    "# split the data into training and testing data (this happen internally).\n",
    "rf_grid.fit(X, y)\n",
    "\n",
    "print(rf_grid.best_score_)\n",
    "print(rf_grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__bootstrap': True, 'classifier__criterion': 'gini', 'classifier__max_depth': 60, 'classifier__max_features': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 8, 'classifier__n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "print(rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model hyperparameters:\n",
      " [('std_scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))]\n"
     ]
    }
   ],
   "source": [
    "# Print pipeline estimator\n",
    "# Pipeline estimator params; estimator is stored as step 2 ([1]), second item ([1])\n",
    "# print('\\nModel hyperparameters:\\n', scale_pipeline.steps[1][1].get_params())\n",
    "print('\\nModel hyperparameters:\\n', scale_pipeline.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle\n",
    "# save the classifier \"rfc\"\n",
    "with open('my_dumped_classifier.pkl', 'wb') as fid:\n",
    "    cPickle.dump(rfc, fid)    \n",
    "\n",
    "# load it again\n",
    "#with open('my_dumped_classifier.pkl', 'rb') as fid:\n",
    "#    gnb_loaded = cPickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get parameters for pipeline object\n",
    "#scale_pipeline.estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Base Model\")\n",
    "print(base_train_acc)\n",
    "print(base_test_acc)\n",
    "\n",
    "#get predictions with best parameters\n",
    "grid_predict = best_grid.predict(X_test)\n",
    "\n",
    "grid_train_acc = accuracy_score(y_train, best_grid.predict(X_train))\n",
    "grid_test_acc = accuracy_score(y_test, grid_predict)\n",
    "print(\"\\n\")\n",
    "print(\"Grid Search Model\")\n",
    "print(grid_train_acc)\n",
    "print(grid_test_acc)\n",
    "\n",
    "#print('Improvement of {:0.2f}%.'.format( 100 * (grid_test_acc - base_test_acc) / base_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "**Base Model**  \n",
    "1.0  \n",
    "0.45652173913\n",
    "\n",
    "**Grid Search Model**  \n",
    "0.895238095238  \n",
    "0.565217391304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_test_acc - base_test_acc) / base_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Accuracy Results\n",
    "**Base Model**\n",
    "```\n",
    "1.0\n",
    "0.45652173913\n",
    "```\n",
    "**Grid Search Model**\n",
    "```\n",
    "1.0\n",
    "0.50\n",
    "```\n",
    "\n",
    "***Improvement of 9.52%. to 50%***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the best model#\n",
    "print('Best Estimator:')\n",
    "print(grid_search.best_estimator_)\n",
    "print()\n",
    "print('Best Score:')\n",
    "print(grid_search.best_score_)\n",
    "print()\n",
    "print('Best Parameters:')\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Estimator**\n",
    "```\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=60, max_features=4, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=5, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "            oob_score=False, random_state=101, verbose=0, warm_start=False)\n",
    "```\n",
    "\n",
    "**Best Score**\n",
    "```\n",
    "0.704761904762\n",
    "```\n",
    "**Best Parameters**\n",
    "```\n",
    "{'bootstrap': True, 'max_depth': 60, 'max_features': 4, 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use new parameters from gridsearch to create and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit classifier with new model parameters from gridsearch\n",
    "rfc = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=60, max_features=4, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=5, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "            oob_score=False, random_state=101, verbose=0, warm_start=False)\n",
    "\n",
    "#Fit model\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "#Predict Classifier\n",
    "rfc_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "rfc_acc = accuracy_score(y_test, rfc_pred)\n",
    "print(rfc_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Feature Importances\n",
    "feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance\")\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "#Output confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "\n",
    "#import libraries to ignore UndefinedMetricWarning\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "#get the model's accuracy score\n",
    "accuracy_score(y_test, rfc_pred)\n",
    "print(\"\\n\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test,rfc_pred))\n",
    "\n",
    "#print accuracy score\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy Score\")\n",
    "print(rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Prediction Classifier on validation data (val_X, val_y)\n",
    "rfc_val_pred = rfc.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "rfc_val_acc = accuracy_score(val_y, rfc_val_pred)\n",
    "print(rfc_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Output confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(val_y, rfc_val_pred))\n",
    "\n",
    "#import libraries to ignore UndefinedMetricWarning\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "#get the model's accuracy score\n",
    "accuracy_score(val_y, rfc_val_pred)\n",
    "print(\"\\n\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(val_y, rfc_val_pred))\n",
    "\n",
    "#print accuracy score\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy Score\")\n",
    "print(rfc.score(val_X, val_y))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
